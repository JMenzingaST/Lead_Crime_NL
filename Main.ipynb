{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assessment Programming 1\n",
    "By: Jacob Menzinga (357758)\n",
    "\n",
    "##### Introduction\n",
    "Research question\n",
    "\n",
    "##### Hypotheses\n",
    "A higher amount of lead in wastewater correlates to a higher incidence of violent crimes\n",
    "\n",
    "##### Data sources\n",
    "1. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=7477&_theme=309\">Wastewater treatment in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Aanvoer van afvalwater -> Hoeveelheden:\n",
    "        - Volume afvalwater in 1000 m3\n",
    "        - Zink in kg\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "\n",
    "2. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=83648NED&_theme=406\">Registered crime in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Geregistreerde misdrijven:\n",
    "        - Geregistreerde misdrijven per 1000 inw.\n",
    "\n",
    "    - Soort misdrijf:\n",
    "        - 111 Diefstal en inbraak met geweld\n",
    "        - 15 Afpersing en afdreiging\n",
    "        - 21 Vernieling en beschadiging\n",
    "        - 221 Openlijke geweldpleging\n",
    "        - 23 Brandstichting / ontploffing\n",
    "        - 3 Gewelds- en seksuele misdrijven\n",
    "        - 7 Vuurwapenmisdrijven\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, show\n",
    "output_notebook()\n",
    "\n",
    "import hvplot.pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(df):\n",
    "    \"\"\"\n",
    "    A function to check any dataframe for:\n",
    "        - Missing data\n",
    "        - Datatypes\n",
    "        - Descriptive statistics\n",
    "        \n",
    "    It then prints it's findings \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe.\n",
    "    \"\"\"\n",
    "    missing_data = df.isna().sum()\n",
    "    if missing_data.values.sum() == 0:\n",
    "        print('Missing data:')\n",
    "        print('No missing data :)')\n",
    "        missing_loc = 'None'\n",
    "    \n",
    "    else:\n",
    "        # missing_data['perc. of data'] = df.isna().sum()/(len(df))*100\n",
    "        missing_loc = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Missing data per column:\\n{missing_data}\\n\")\n",
    "        print(\"The missing data is located in the following rows:\")\n",
    "        print(missing_loc)\n",
    "    \n",
    "    \n",
    "    dtypes = df.dtypes\n",
    "    print('\\nData types:')\n",
    "    print(dtypes)\n",
    "    \n",
    "    describe = df.describe()\n",
    "    print(f'\\nDescription of the dataframe')\n",
    "    print(describe)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "crime_df = pd.read_csv(config['crime'], delimiter=';')\n",
    "lead_df = pd.read_csv(config['lead'], delimiter=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll have a look at crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.rename(columns= {'SoortMisdrijf':'Crime',\n",
    "                         'RegioS':'Region', 'Perioden':'Year',\n",
    "                         'GeregistreerdeMisdrijvenPer1000Inw_3':'Incidence'},\n",
    "                inplace=True)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data(crime_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things I took away from the datacheck:\n",
    "1) There are a lot of missing values in the PV99 region. I looked this region code up in the metadata file of the crime dataset (also downloadable from the above link) and this is a category for 'uncatogarisable'data so I will drop these rows.\n",
    "\n",
    "2) I want to turn the Year and Incidence columns into int and float dtypes respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the PV99 region\n",
    "crime_df = crime_df[crime_df['Region'] != 'PV99  ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the Incidence and Year columns\n",
    "print(crime_df['Incidence'].unique())\n",
    "print(crime_df['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the '       .' value with 0\n",
    "# Verklaring waarom.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "crime_df['Incidence'] = crime_df['Incidence'].str.replace('       .', '0', regex=False)\n",
    "\n",
    "# Typecasting the Year and Incidence columns\n",
    "crime_df['Year'] = crime_df['Year'].str.replace('JJ00','').astype(int)\n",
    "crime_df['Incidence'] = crime_df['Incidence'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that that's done, I'll run the check data again to see if I got rid of \n",
    "# all the missing data\n",
    "\n",
    "check_data(crime_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_df.rename(columns={'RegioS':'Region', 'Perioden':'Year',\n",
    "                        'VolumeAfvalwater_43':'Vol_Wastewater', \n",
    "                        'Lood_52':'Lead'}, inplace= True)\n",
    "lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data(lead_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataframe I want to change the Year and Lead columns to intergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lead_df['Lead'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  replacing the '       .' value with NaN\n",
    "lead_df['Lead'] = lead_df['Lead'].replace('       .', np.nan, regex=False)\n",
    "\n",
    "# Typecasting the Year and Lead columns\n",
    "lead_df['Year'] = lead_df['Year'].str.replace('JJ00','').astype(int)\n",
    "lead_df['Lead'] = lead_df['Lead'].astype(float) # Float for now because NaN can't be int.\n",
    "\n",
    "# Filling the NaN with an interpolated value\n",
    "lead_df['Lead'] = lead_df['Lead'].interpolate().astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the amount of wastewater in 1000 m3 and the amount of lead in the water in kg, I would like to create a column with the amount of lead per m3 of water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_df['lead_per_m3'] = lead_df['Lead'] / lead_df['Vol_Wastewater']\n",
    "# Converting lead from kilogram to gram\n",
    "lead_df['lead_per_m3'] = lead_df['lead_per_m3']*1000\n",
    "lead_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to have a look at the Region column in both DataFrames, since this is the feature I'll be merging on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Region'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Region'].unique()}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There clearly is some whitespace that needs removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Region'] = crime_df['Region'].str.replace(r'\\s','', regex=True)\n",
    "lead_df['Region'] = lead_df['Region'].str.replace(r'\\s','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Region'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Region'].unique()}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crime_df has the different types of crime in one column, I would like each crime as a different feature with he incedence as their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = crime_df.set_index(['Region','Year']).pivot(columns='Crime', values='Incidence').reset_index()\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Total_incidence'] = crime_df[[\n",
    "    'CRI1110', 'CRI1500', 'CRI2100', 'CRI2200', 'CRI2300','CRI3000', 'CRI7000']].sum(axis=1)\n",
    "crime_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both dataframes are ready to be merged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_crime_df = lead_df.merge(crime_df, how='inner', on=['Region', 'Year'])\n",
    "lead_crime_df = lead_crime_df.drop(['Vol_Wastewater', 'Lead', 'ID'], axis=1)\n",
    "\n",
    "lead_crime_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the dataframe I'll be working with to answer my research question. Below I'll provide some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvexplorer = hvplot.explorer(lead_crime_df)\n",
    "hvexplorer\n",
    "# Check for normal distribution\n",
    "# Check for independence \n",
    "# Seaborn Pairplot / heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
