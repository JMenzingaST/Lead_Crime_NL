{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assessment Programming 1\n",
    "By: Jacob Menzinga (357758)\n",
    "\n",
    "##### Introduction\n",
    "Research question\n",
    "\n",
    "##### Hypotheses\n",
    "A higher amount of lead in wastewater correlates to a higher incidence of violent crimes\n",
    "\n",
    "##### Data sources\n",
    "1. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=7477&_theme=309\">Wastewater treatment in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Aanvoer van afvalwater -> Hoeveelheden:\n",
    "        - Volume afvalwater in 1000 m3\n",
    "        - Lood in kg\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "\n",
    "2. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=83648NED&_theme=406\">Registered crime in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Geregistreerde misdrijven:\n",
    "        - Geregistreerde misdrijven per 1000 inw.\n",
    "\n",
    "    - Soort misdrijf:\n",
    "        - 111 Diefstal en inbraak met geweld\n",
    "        - 15 Afpersing en afdreiging\n",
    "        - 21 Vernieling en beschadiging\n",
    "        - 221 Openlijke geweldpleging\n",
    "        - 23 Brandstichting / ontploffing\n",
    "        - 3 Gewelds- en seksuele misdrijven\n",
    "        - 7 Vuurwapenmisdrijven\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, show\n",
    "output_notebook()\n",
    "\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import DS_Module as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(df):\n",
    "    \"\"\"\n",
    "    A function to check any dataframe for:\n",
    "        - Missing data\n",
    "        - Datatypes\n",
    "        - Descriptive statistics\n",
    "        \n",
    "    It then prints it's findings \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe.\n",
    "    \"\"\"\n",
    "    missing_data = df.isna().sum()\n",
    "    if missing_data.values.sum() == 0:\n",
    "        print('Missing data:')\n",
    "        print('No missing data :)')\n",
    "        missing_loc = 'None'\n",
    "    \n",
    "    else:\n",
    "        # missing_data['perc. of data'] = df.isna().sum()/(len(df))*100\n",
    "        missing_loc = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Missing data per column:\\n{missing_data}\\n\")\n",
    "        print(\"The missing data is located in the following rows:\")\n",
    "        print(missing_loc)\n",
    "    \n",
    "    \n",
    "    dtypes = df.dtypes\n",
    "    print('\\nData types:')\n",
    "    print(dtypes)\n",
    "    \n",
    "    describe = df.describe()\n",
    "    print(f'\\nDescription of the dataframe')\n",
    "    print(describe)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "crime_df = pd.read_csv(config['crime'], delimiter=';')\n",
    "lead_df = pd.read_csv(config['lead'], delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll have a look at crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.rename(columns= {'SoortMisdrijf':'Crime',\n",
    "                         'RegioS':'Provence', 'Perioden':'Year',\n",
    "                         'GeregistreerdeMisdrijvenPer1000Inw_3':'Incidence'},\n",
    "                inplace=True)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_data(crime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things I took away from the datacheck:\n",
    "1) There are a lot of missing values in the PV99 region. I looked this region code up in the metadata file of the crime dataset (also downloadable from the above link) and this is a category for 'uncatogarisable'data so I will drop these rows.\n",
    "\n",
    "2) I want to turn the Year and Incidence columns into int and float dtypes respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the PV99 region\n",
    "crime_df = crime_df[crime_df['Provence'] != 'PV99  ']\n",
    "crime_df\n",
    "# This seems to have messed up the index a bit, \n",
    "# concidering there's 924 rows in the df but the index gows up to 989."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = crime_df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the Incidence and Year columns\n",
    "print(crime_df['Incidence'].unique())\n",
    "print(crime_df['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm assuming the '       .' values for incidence should be 0, to check this \n",
    "# I want to plot the 5 datapoints before these values to see if they show \n",
    "# a trend decreasing toward 0\n",
    "missing_crime = crime_df[crime_df['Incidence']=='       .'].index\n",
    "missing_crime = np.array(missing_crime)\n",
    "\n",
    "trend_ind = np.empty(0)\n",
    "\n",
    "for i in range (6):\n",
    "    trend_ind = np.append(trend_ind, missing_crime-i)\n",
    "    \n",
    "trend_ind = np.unique(trend_ind)\n",
    "\n",
    "# this list I will use after after replacing the '.' values to 0 to check if \n",
    "# my assumption was correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing the '       .' value with 0\n",
    "crime_df['Incidence'] = crime_df['Incidence'].str.replace('       .', '0', regex=False)\n",
    "\n",
    "# Typecasting the Year and Incidence columns\n",
    "crime_df['Year'] = crime_df['Year'].str.replace('JJ00','').astype(int)\n",
    "crime_df['Incidence'] = crime_df['Incidence'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.iloc[trend_ind].sort_values(by='Year').hvplot.scatter(x='Year', y='Incidence', groupby=['Crime', 'Provence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that that's done, I'll run the check data again to see if I got rid of all the missing data\n",
    "\n",
    "check_data(crime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_df.rename(columns={'RegioS':'Provence', 'Perioden':'Year',\n",
    "                        'VolumeAfvalwater_43':'Vol_Wastewater', \n",
    "                        'Lood_52':'Lead'}, inplace= True)\n",
    "lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data(lead_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataframe I want to change the Year and Lead columns to intergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lead_df['Lead'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dataset there's also '    .' values. I want to have a look at the \n",
    "# A value of 0kg lead in the wastewater does not make sense to me given all the \n",
    "# other values are at least above 100, ald the vol_wastewater is not decreased. \n",
    "# I'm going to interpolate these values and plot them between non interpolated \n",
    "# values to see if this makes sense\n",
    "\n",
    "missing_lead = lead_df[lead_df['Lead']=='       .'].index\n",
    "missing_lead = np.array(missing_lead)\n",
    "\n",
    "lead_plus_min = np.append(missing_lead-1, missing_lead+1)\n",
    "lead_plus_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  replacing the '       .' value with NaN\n",
    "lead_df['Lead'] = lead_df['Lead'].replace('       .', np.nan, regex=False)\n",
    "\n",
    "# Typecasting the Year and Lead columns\n",
    "lead_df['Year'] = lead_df['Year'].str.replace('JJ00','').astype(int)\n",
    "lead_df['Lead'] = lead_df['Lead'].astype(float) # Float for now because NaN can't be int.\n",
    "\n",
    "# Filling the NaN with an interpolated value\n",
    "lead_df['Lead'] = lead_df['Lead'].interpolate().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to check if the interpolated data make sense\n",
    "\n",
    "measured_lead_scatter = lead_df.iloc[lead_plus_min\n",
    "                                     ].hvplot.scatter(x='Vol_Wastewater',\n",
    "                                                      y='Lead',\n",
    "                                                      label='Experimental data')\n",
    "\n",
    "interpolated_lead_scatter = lead_df.iloc[missing_lead\n",
    "                                     ].hvplot.scatter(x='Vol_Wastewater',\n",
    "                                                      y='Lead', color='red',\n",
    "                                                      label='Interpolated data')\n",
    "                                     \n",
    "factcheck = measured_lead_scatter * interpolated_lead_scatter\n",
    "factcheck.opts(title='Measuered and interpolated lead data',\n",
    "               ylabel='Lead (kg)', xlabel='Volume Infulent Wastewater (m3)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the amount of wastewater in 1000 m3 and the amount of lead in the water in kg, I would like to create a column with the amount of lead per m3 of water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_df['lead_per_m3'] = lead_df['Lead'] / lead_df['Vol_Wastewater']\n",
    "# Converting lead from kilogram to gram\n",
    "lead_df['lead_per_m3'] = lead_df['lead_per_m3']*1000\n",
    "lead_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to have a look at the Region column in both DataFrames, since this is the feature I'll be merging on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Provence'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Provence'].unique()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There clearly is some whitespace that needs removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Provence'] = crime_df['Provence'].str.replace(r'\\s','', regex=True)\n",
    "lead_df['Provence'] = lead_df['Provence'].str.replace(r'\\s','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Provence'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Provence'].unique()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crime_df has the different types of crime in one column, I would like each crime as a different feature with he incedence as their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = crime_df.set_index(['Provence','Year']).pivot(columns='Crime', values='Incidence').reset_index()\n",
    "crime_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also a total incidence would be usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Total_incidence'] = crime_df[[\n",
    "    'CRI1110', 'CRI1500', 'CRI2100', 'CRI2210', 'CRI2300', 'CRI3000', 'CRI7000']\n",
    "                                       ].sum(axis=1)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both dataframes are ready to be merged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_crime_df = lead_df.merge(crime_df, how='inner', on=['Provence', 'Year'], \n",
    "                              copy=True)\n",
    "lead_crime_df = lead_crime_df.drop(['Vol_Wastewater', 'Lead', 'ID'], axis=1)\n",
    "lead_crime_df['Provence'] = lead_crime_df['Provence'].map({'PV20': 'Groningen',\n",
    "                                                           'PV21': 'Fryslân',\n",
    "                                                           'PV22': 'Drenthe',\n",
    "                                                           'PV23': 'Overijssel',\n",
    "                                                           'PV24': 'Flevoland',\n",
    "                                                           'PV25': 'Gelderland',\n",
    "                                                           'PV26': 'Utrecht',\n",
    "                                                           'PV27': 'Noord-Holland',\n",
    "                                                           'PV28': 'Zuid-Holland',\n",
    "                                                           'PV29': 'Zeeland',\n",
    "                                                           'PV30': 'Noord-Brabant',\n",
    "                                                           'PV31': 'Limburg'})\n",
    "\n",
    "lead_crime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the dataframe I'll be working with to answer my research question. Below I'll provide some information\n",
    "\n",
    "Columns:\n",
    "    lead_per_m3: This is the amount of grams of lead found in the incoming waste water\n",
    "    Incidence: This is the incidence of violent crimes per 100.000 inhabitants of a given provence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.DS_Q_Q_Plot(crime_df['Total_incidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds.DS_Q_Q_Plot(lead_df['lead_per_m3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram normaal verdeling\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_crime_df[['lead_per_m3','Total_incidence']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_crime_df.hvplot(kind='line', x='Year', \n",
    "                     y=['lead_per_m3','Total_incidence'], \n",
    "                     groupby='Provence', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizeren data bovenstaande grafiek\n",
    "# Multi-axis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Crimes = ['CRI1110', 'CRI1500', 'CRI2100', 'CRI2210', 'CRI2300', 'CRI3000', 'CRI7000']\n",
    "lead_crime_df.set_index('Provence').hvplot(kind='bar', stacked=True, \n",
    "                                           y=Crimes, groupby='Year', \n",
    "                                           ylim=(0,25), rot=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer my research question - Is there a correlation between lead in water and violent crimes - I'm going to perform a Pearson Correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onderbouwen regressie en de checks\n",
    "# Onderstaande per provincie\n",
    "# Testen voor outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "correlation, p_val = pearsonr(lead_crime_df['lead_per_m3'], lead_crime_df['Total_incidence'])\n",
    "print(f\"\"\"\n",
    "The correlation between the lead per cubic meter of water and total incidence of violent crimes is {correlation:.2f}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_data = hv.Scatter(data=lead_crime_df, kdims='lead_per_m3', vdims='Total_incidence')\n",
    "scatter = lead_crime_df.hvplot.scatter(x='lead_per_m3',\n",
    "                             y='Total_incidence',\n",
    "                             xlabel='Lead per m3 of water (in grams)',\n",
    "                             ylabel='Total incidence per 100.000 inhabitants',\n",
    "                             title='Ja')\n",
    "\n",
    "Regression_line = hv.Slope.from_scatter(scatter_data).opts(color='black')\n",
    "\n",
    "scatter * Regression_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inladen\n",
    "# Cleanen\n",
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geoplotten\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "\n",
    "m = folium.Map(location=[52.2594406805025, 4.952074743739346],\n",
    "               zoom_start=7)\n",
    "minimap = plugins.MiniMap(toggle_display=True)\n",
    "\n",
    "m.add_child(minimap)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
