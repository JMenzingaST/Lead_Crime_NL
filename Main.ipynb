{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assessment Programming 1\n",
    "By: Jacob Menzinga (357758)\n",
    "\n",
    "##### Introduction\n",
    "In the united states the crime rates steadily increased up untill the 1990's. Then, a sharp decrease in crime rates was observed. To explain this decrease, researchers have come up with multple reasons. One factor that drew attention was lead exposure. This lead to the Lead-Crime hypothesis. A lot of papers since have been published on this. One example is a meta analysis published by Anthony Higney, et al. (2022) in wich they write: \"Our estimates suggest the abatement of lead pollution may be responsible for 7â€“28% of the fall in homicide in the US\"\n",
    "\n",
    "For the final asessment of programming 1 I decided to investigate if such a relation is also visible in the netherlands. To take blood-lead values of the whole population of the Netherlands is a bit unethical and expensive so I decided to look at the amount of lead in  wastewater instead\n",
    "\n",
    "##### Hypotheses\n",
    "A higher amount of lead in wastewater correlates to a higher incidence of violent crimes\n",
    "\n",
    "##### Data sources\n",
    "1. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=7477&_theme=309\">Wastewater treatment in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Aanvoer van afvalwater -> Hoeveelheden:\n",
    "        - Volume afvalwater in 1000 m3\n",
    "        - Lood in kg\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "\n",
    "2. <a href=\"https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=83648NED&_theme=406\">Registered crime in the netherlands</a><br>\n",
    "From this dataset the following features were selected:\n",
    "\n",
    "    - Onderwerpen -> Geregistreerde misdrijven:\n",
    "        - Geregistreerde misdrijven per 1000 inw.\n",
    "\n",
    "    - Soort misdrijf:\n",
    "        - 111 Diefstal en inbraak met geweld\n",
    "        - 15 Afpersing en afdreiging\n",
    "        - 21 Vernieling en beschadiging\n",
    "        - 221 Openlijke geweldpleging\n",
    "        - 23 Brandstichting / ontploffing\n",
    "        - 3 Gewelds- en seksuele misdrijven\n",
    "        - 7 Vuurwapenmisdrijven\n",
    "\n",
    "    - Regios:\n",
    "        - Provincies\n",
    "\n",
    "    - Perioden:\n",
    "        - from 2010 up to and including 2020\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, show\n",
    "output_notebook()\n",
    "\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "import DS_Module as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(df):\n",
    "    \"\"\"\n",
    "    A function to check any dataframe for:\n",
    "        - Missing data\n",
    "        - Datatypes\n",
    "        - Descriptive statistics\n",
    "        \n",
    "    It then prints it's findings \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Any dataframe.\n",
    "    \"\"\"\n",
    "    missing_data = df.isna().sum()\n",
    "    if missing_data.values.sum() == 0:\n",
    "        print('Missing data:')\n",
    "        print('No missing data :)')\n",
    "        missing_loc = 'None'\n",
    "    \n",
    "    else:\n",
    "        # missing_data['perc. of data'] = df.isna().sum()/(len(df))*100\n",
    "        missing_loc = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Missing data per column:\\n{missing_data}\\n\")\n",
    "        print(\"The missing data is located in the following rows:\")\n",
    "        print(missing_loc)\n",
    "    \n",
    "    \n",
    "    dtypes = df.dtypes\n",
    "    print('\\nData types:')\n",
    "    print(dtypes)\n",
    "    \n",
    "    describe = df.describe()\n",
    "    print(f'\\nDescription of the dataframe')\n",
    "    print(describe)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "crime_df = pd.read_csv(config['crime'], delimiter=';')\n",
    "lead_df = pd.read_csv(config['lead'], delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll have a look at crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.rename(columns= {'SoortMisdrijf':'Crime',\n",
    "                         'RegioS':'Provence', 'Perioden':'Year',\n",
    "                         'GeregistreerdeMisdrijvenPer1000Inw_3':'Incidence'},\n",
    "                inplace=True)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_data(crime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things I took away from the datacheck:\n",
    "1) There are a lot of missing values in the PV99 region. I looked this region code up in the metadata file of the crime dataset (also downloadable from the above link) and this is a category for 'uncatogarisable' data so I will drop these rows.\n",
    "\n",
    "2) I want to turn the Year and Incidence columns into int and float dtypes respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the PV99 region\n",
    "crime_df = crime_df[crime_df['Provence'] != 'PV99  ']\n",
    "crime_df\n",
    "# This seems to have messed up the index a bit, \n",
    "# concidering there's 924 rows in the df but the index gows up to 989."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = crime_df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the Incidence and Year columns\n",
    "print(crime_df['Incidence'].unique())\n",
    "print(crime_df['Year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm assuming the '       .' values for incidence should be 0, to check this I want to plot the 5 datapoints before these values to see if they show a trend decreasing toward 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_crime = crime_df[crime_df['Incidence']=='       .'].index\n",
    "missing_crime = np.array(missing_crime)\n",
    "\n",
    "trend_ind = np.empty(0)\n",
    "\n",
    "for i in range (6):\n",
    "    trend_ind = np.append(trend_ind, missing_crime-i)\n",
    "    \n",
    "trend_ind = np.unique(trend_ind)\n",
    "\n",
    "# this list I will use after after replacing the '.' values to 0 to check if \n",
    "# my assumption was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing the '       .' value with 0\n",
    "crime_df['Incidence'] = crime_df['Incidence'].str.replace('       .', '0', regex=False)\n",
    "\n",
    "# Typecasting the Year and Incidence columns\n",
    "crime_df['Year'] = crime_df['Year'].str.replace('JJ00','').astype(int)\n",
    "crime_df['Incidence'] = crime_df['Incidence'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the incidence, per region and crime. 0 values are interpolated.\n",
    "hv.output(widget_location='top_left')\n",
    "crime_df.iloc[trend_ind\n",
    "             ].sort_values(by='Year').hvplot.line(x='Year', \n",
    "                                                  y='Incidence', \n",
    "                                                  groupby=['Crime', 'Provence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that that's done, I'll run the check data again to see if I got rid of all the missing data\n",
    "check_data(crime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crime_df has the different types of crime in one column, I would like each crime as a different feature with he incedence as their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crime_df = crime_df.set_index(['Provence','Year']).pivot(columns='Crime', values='Incidence').reset_index()\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also a total incidence would be usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crime_df['Total_incidence'] = crime_df[[\n",
    "    'CRI1110', 'CRI1500', 'CRI2100', 'CRI2210', 'CRI2300', 'CRI3000', 'CRI7000']\n",
    "                                       ].sum(axis=1)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_df.rename(columns={'RegioS':'Provence', 'Perioden':'Year',\n",
    "                        'VolumeAfvalwater_43':'Vol_Wastewater', \n",
    "                        'Lood_52':'Lead'}, inplace= True)\n",
    "lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First some general information\n",
    "check_data(lead_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataframe I want to change the Year and Lead columns to intergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lead_df['Lead'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset there's also '       .' values.\n",
    "A value of 0kg lead in the wastewater does not make sense to me given all the other values are at least above 100, and the vol_wastewater is not decreased in these rows. \n",
    "\n",
    "I'm going to interpolate these values and plot them between non interpolated values to see if this makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_lead = lead_df[lead_df['Lead']=='       .'].index\n",
    "missing_lead = np.array(missing_lead)\n",
    "\n",
    "lead_plus_min = np.append(missing_lead-1, missing_lead+1)\n",
    "lead_plus_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  replacing the '       .' value with NaN\n",
    "lead_df['Lead'] = lead_df['Lead'].replace('       .', np.nan, regex=False)\n",
    "\n",
    "# Typecasting the Year and Lead columns\n",
    "lead_df['Year'] = lead_df['Year'].str.replace('JJ00','').astype(int)\n",
    "lead_df['Lead'] = lead_df['Lead'].astype(float) # Float for now because NaN can't be int.\n",
    "\n",
    "# Filling the NaN with an interpolated value\n",
    "lead_df['Lead'] = lead_df['Lead'].interpolate().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to check if the interpolated data make sense\n",
    "\n",
    "measured_lead_scatter = lead_df.iloc[lead_plus_min\n",
    "                                     ].hvplot.scatter(x='Vol_Wastewater',\n",
    "                                                      y='Lead',\n",
    "                                                      label='Experimental data')\n",
    "\n",
    "interpolated_lead_scatter = lead_df.iloc[missing_lead\n",
    "                                     ].hvplot.scatter(x='Vol_Wastewater',\n",
    "                                                      y='Lead', color='red',\n",
    "                                                      label='Interpolated data')\n",
    "                                     \n",
    "factcheck = measured_lead_scatter * interpolated_lead_scatter\n",
    "factcheck.opts(title='Measuered and interpolated lead data',\n",
    "               ylabel='Lead (kg)', xlabel='Volume Infulent Wastewater (m3)',\n",
    "               legend_position='top_left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the amount of wastewater in 1000 m3 and the amount of lead in the water in kg, I would like to create a column with the amount of lead per m3 of water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_df['lead_per_m3'] = lead_df['Lead'] / lead_df['Vol_Wastewater']\n",
    "# Converting lead from kilogram to gram\n",
    "lead_df['lead_per_m3'] = lead_df['lead_per_m3']*1000\n",
    "lead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lets check the data again now we're done cleaning and interpolating values.\n",
    "check_data(lead_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to have a look at the Region column in both DataFrames, since this is the feature I'll be merging on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Provence'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Provence'].unique()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There clearly is some whitespace that needs removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Provence'] = crime_df['Provence'].str.replace(r'\\s','', regex=True)\n",
    "lead_df['Provence'] = lead_df['Provence'].str.replace(r'\\s','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Crime regions:\n",
    "{crime_df['Provence'].unique()}\n",
    "\n",
    "Lead regions:\n",
    "{lead_df['Provence'].unique()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both dataframes are ready to be merged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_crime_df = lead_df.merge(crime_df, how='inner', on=['Provence', 'Year'], \n",
    "                              copy=True)\n",
    "lead_crime_df = lead_crime_df.drop(['Vol_Wastewater', 'Lead', 'ID'], axis=1)\n",
    "lead_crime_df['Provence'] = lead_crime_df['Provence'].map({'PV20': 'Groningen',\n",
    "                                                           'PV21': 'FryslÃ¢n',\n",
    "                                                           'PV22': 'Drenthe',\n",
    "                                                           'PV23': 'Overijssel',\n",
    "                                                           'PV24': 'Flevoland',\n",
    "                                                           'PV25': 'Gelderland',\n",
    "                                                           'PV26': 'Utrecht',\n",
    "                                                           'PV27': 'Noord-Holland',\n",
    "                                                           'PV28': 'Zuid-Holland',\n",
    "                                                           'PV29': 'Zeeland',\n",
    "                                                           'PV30': 'Noord-Brabant',\n",
    "                                                           'PV31': 'Limburg'})\n",
    "\n",
    "lead_crime_df.rename(columns={'CRI1110':'Violent theft and burglary',\n",
    "                              'CRI1500':'Extortion',\n",
    "                              'CRI2100':'Vandalism',\n",
    "                              'CRI2210':'Public violence',\n",
    "                              'CRI2300':'Arson / Explosion',\n",
    "                              'CRI3000':'Violent an sexual crimes',\n",
    "                              'CRI7000':'Firearms crimes'},\n",
    "                     inplace=True)\n",
    "\n",
    "lead_crime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the dataframe I'll be working with to answer my research question. Below I'll provide some information\n",
    "\n",
    "Columns:\n",
    "- lead_per_m3: This is the amount of grams of lead found in the incoming waste water\n",
    "- Incidence: This is the incidence of violent crimes per 100.000 inhabitants of a province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.DS_Q_Q_Plot(crime_df['Total_incidence'])\n",
    "ds.DS_Q_Q_Hist(crime_df['Total_incidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds.DS_Q_Q_Plot(lead_df['lead_per_m3'])\n",
    "ds.DS_Q_Q_Hist(lead_df['lead_per_m3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram of the total crime incidence values it's clear this data is not normally distributed. I'll take this into account when calculating a correlation between lead and crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the lead and total indicende behave together I will plot them together on a line plot over time. To account for the difference in y-values I'll first normaize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lead_crime = lead_crime_df[['Provence','Year',\n",
    "                                       'lead_per_m3','Total_incidence']].copy()\n",
    "\n",
    "for col in ['lead_per_m3', 'Total_incidence']:\n",
    "    \n",
    "    df_max = normalized_lead_crime[col].max()\n",
    "    df_min = normalized_lead_crime[col].min()\n",
    "    df_range = df_max - df_min\n",
    "\n",
    "    normalized_lead_crime[col] = normalized_lead_crime[col\n",
    "                                    ].apply(lambda x: ((x-df_min)/df_range))\n",
    "\n",
    "normalized_lead_crime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalized_lead_crime.hvplot(kind='line', x='Year', \n",
    "                     y=['lead_per_m3','Total_incidence'], \n",
    "                     groupby='Provence').opts(legend_position='top_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two observations here:\n",
    "- In all provinces the incidence of violent crimes decrease over time (hooray).\n",
    "- The lead content in inffluent waste water in most provencesjumps around over time. Sometime ending a higher, sometimes lower. Not very hopeful for a strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Crimes = ['Violent theft and burglary','Extortion', 'Vandalism', \n",
    "          'Public violence', 'Arson / Explosion', 'Violent an sexual crimes', \n",
    "          'Firearms crimes']\n",
    "\n",
    "hv.output(widget_location='top_left')\n",
    "lead_crime_df.set_index('Provence'\n",
    "                        ).hvplot(kind='bar', stacked=True,\n",
    "                                 y=Crimes, groupby='Year',\n",
    "                                 ylim=(0,25), title='Crimes per region, per year.',\n",
    "                                 ylabel='Incidence per 100.000 inhabitants',\n",
    "                                 rot=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer my research question - Is there a correlation between lead in water and violent crimes - I'm going to perform a Pearson Correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onderbouwen regressie en de checks\n",
    "# Onderstaande per provincie\n",
    "# Testen voor outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "correlation, p_val = spearmanr(lead_crime_df['lead_per_m3'], \n",
    "                              lead_crime_df['Total_incidence'])\n",
    "print(f\"\"\"\n",
    "The correlation between the lead per cubic meter of water and\n",
    "total incidence of violent crimes is {correlation:.2f}, p value: {p_val}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_data = hv.Scatter(data=lead_crime_df, kdims='lead_per_m3', \n",
    "                          vdims='Total_incidence', label='Regression line')\n",
    "scatter = lead_crime_df.hvplot.scatter(\n",
    "                            x='lead_per_m3',\n",
    "                            y='Total_incidence',\n",
    "                            xlabel='Lead per m3 of water (in grams)',\n",
    "                            ylabel='Total incidence per 100.000 inhabitants',\n",
    "                            label='Data',\n",
    "                            title='Ja')\n",
    "\n",
    "Regression_line = hv.Slope.from_scatter(scatter_data).opts(color='black')\n",
    "\n",
    "scatter.opts(legend_position='top_right') * Regression_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above graph we see four datapoints that seem to be a bit out of the ordinary. \n",
    "# I'm going to dorp them to see if this has any impact.\n",
    "\n",
    "to_drop = lead_crime_df[(lead_crime_df['lead_per_m3'] < 6) &\n",
    "                        (lead_crime_df['Total_incidence'] > 18)\n",
    "                        ].index.tolist()\n",
    "\n",
    "to_drop.extend(lead_crime_df[(lead_crime_df['lead_per_m3'] > 35) & \n",
    "                             (lead_crime_df['Total_incidence'] < 14)\n",
    "                             ].index.tolist())\n",
    "to_drop\n",
    "\n",
    "lead_crime_df.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation, p_val = spearmanr(lead_crime_df['lead_per_m3'], \n",
    "                              lead_crime_df['Total_incidence'])\n",
    "print(f\"\"\"\n",
    "The correlation between the lead per cubic meter of water and\n",
    "total incidence of violent crimes is {correlation:.2f}, p value: {p_val}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So while this does impact the correlation somewhat, \n",
    "# it does not increase it to a significant level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_data = hv.Scatter(data=lead_crime_df, kdims='lead_per_m3', \n",
    "                          vdims='Total_incidence')\n",
    "\n",
    "scatter = lead_crime_df.hvplot.scatter(\n",
    "                            x='lead_per_m3',\n",
    "                            y='Total_incidence',\n",
    "                            xlabel='Lead per m3 of water (in grams)',\n",
    "                            ylabel='Total incidence per 100.000 inhabitants',\n",
    "                            label='Data',\n",
    "                            title='Ja')\n",
    "\n",
    "Regression_line2 = hv.Slope.from_scatter(scatter_data).opts(color='red')\n",
    "\n",
    "(scatter.opts(legend_position='top_right') * Regression_line\n",
    " * Regression_line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is confirmed visually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at the total incidence and lead per m3 of water, there is no significant correlation. Next I'm going to look at the data per provence to see if there are trends visible on a smaller scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_lead_crime_province = lead_crime_df[['lead_per_m3','Total_incidence','Provence']\n",
    "                                        ].groupby('Provence'\n",
    "                                        ).corr(method='spearman').reset_index(\n",
    "                                            )[::2][['Provence','Total_incidence']]\n",
    "\n",
    "corr_lead_crime_province.rename(columns={'Total_incidence':'Correlation lead & crime'}, \n",
    "                                inplace=True)\n",
    "\n",
    "corr_lead_crime_province.set_index('Provence').hvplot.bar(rot=40,\n",
    "                                                         xlabel='Provence of the Netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify per crime and / or Provence\n",
    "scatter_data = hv.Scatter(data=lead_crime_df, kdims='lead_per_m3', \n",
    "                          vdims='Total_incidence', label='Regression line')\n",
    "\n",
    "scatter = lead_crime_df.hvplot.scatter(\n",
    "                            x='lead_per_m3',\n",
    "                            y='Total_incidence',\n",
    "                            groupby='Provence',\n",
    "                            xlabel='Lead per m3 of water (in grams)',\n",
    "                            ylabel='Total incidence per 100.000 inhabitants',\n",
    "                            label='Data', title='Ja', subplots=True)\n",
    "\n",
    "Regression_line2 = hv.Slope.from_scatter(scatter_data).opts(color='red')\n",
    "\n",
    "scatter.opts(legend_position='top_right') * Regression_line * Regression_line2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I want to plot the incidence and lead per m3 of wastewater per provence, over a map of the Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Geoplotten\n",
    "\n",
    "def get_map():\n",
    "    m = folium.Map(location=[52.2594406805025, 4.952074743739346],\n",
    "                   zoom_start=7)\n",
    "    \n",
    "    url = 'https://www.webuildinternet.com/articles/2015-07-19-geojson-data-of-the-netherlands/provinces.geojson'\n",
    "\n",
    "    \n",
    "    borderstyle = {\n",
    "        'color' : 'black',\n",
    "        'fill' : False,\n",
    "        'weight' : 1\n",
    "    }\n",
    "    \n",
    "    border = folium.GeoJson(data=url, name='borders', \n",
    "                             style_function= lambda x: borderstyle, \n",
    "                             control = False).add_to(m)\n",
    "\n",
    "    incidence = folium.Choropleth(\n",
    "        geo_data=url,\n",
    "        name=\"Incidence\",\n",
    "        data=lead_crime_df.replace('FryslÃ¢n', 'Friesland (FryslÃ¢n)'),\n",
    "        columns=[\"Provence\", \"Total_incidence\"],\n",
    "        key_on=\"properties.name\", # Thanks to job for helping me figure out wich value to use here!\n",
    "        fill_color=\"YlOrRd\",\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=1,\n",
    "        legend_name=\"Total violent crime incidence (per 100.000 inhabitants)\",\n",
    "        show = False\n",
    "    ).add_to(m)\n",
    "\n",
    "    lead = folium.Choropleth(\n",
    "            geo_data=url,\n",
    "            name=\"Lead\",\n",
    "            data=lead_crime_df.replace('FryslÃ¢n', 'Friesland (FryslÃ¢n)'),\n",
    "            columns=[\"Provence\", \"lead_per_m3\"],\n",
    "            key_on=\"properties.name\",\n",
    "            fill_color=\"BuPu\",\n",
    "            fill_opacity=0.7,\n",
    "            line_opacity=1,\n",
    "            legend_name=\"Total violent crime incidence (per 100.000 inhabitants)\",\n",
    "            show = False,\n",
    "            hilight = True\n",
    "    ).add_to(m)\n",
    "\n",
    "    minimap = plugins.MiniMap(toggle_display=True)\n",
    "    m.add_child(minimap)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "mapobject = get_map()\n",
    "mapobject.save('Lead & Crime incidence NL.html')\n",
    "\n",
    "mapobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: There is no significant correlation between lead found in wastewater and violent crimes, anywhere in the Netherlands. Only in the provence Overijssel there is a somewhat strong negative correlation between lead in influent waste water and violent crime but looking at the rest of the data, I suspect this does not indicate any causation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b91fa5cffef32cb10787a50fea9666676a7951181e01280b4644cd70c964bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
